---
title: 'Lab 2: More on Degree and Cognative Social Structures'
author: "Zack W Almquist (University of Minnesota)"
date: "June 12, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(sna)                      # Load the sna library
library(networkMethods)
library(networkdata)
```

## Load Data
```{r}
data(mids_1993)
data(contig_1993)
```

```{r}
#
#Basic centrality indices: degree, betweenness, and closeness-------------------
#
# We begin with the simplest case: degree
degree(mids_1993)                                        # Default: total degree
ideg <- degree(mids_1993, cmode="indegree")              # Indegree for MIDs
odeg <- degree(mids_1993, cmode="outdegree")             # Outdegree for MIDs
all(degree(mids_1993) == ideg+odeg)                      # In + out = total?
```

```{r}
# Once centrality scores are computed, we can handle them using standard R 
# methods:
plot(ideg, odeg, type="n", xlab="Incoming MIDs", ylab="Outgoing MIDs")
abline(0, 1, lty=3)
text(jitter(ideg), jitter(odeg), network.vertex.names(contig_1993), cex=0.75, 
    col=2)   #Plot index by odeg
```

```{r}
#Plot simple histograms of the degree distribution:
par(mfrow=c(2,2))                                       # Set up a 2x2 display
hist(ideg, xlab="Indegree", main="Indegree Distribution", prob=TRUE)
hist(odeg, xlab="Outdegree", main="Outdegree Distribution", prob=TRUE)
hist(ideg+odeg, xlab="Total Degree", main="Total Degree Distribution", 
    prob=TRUE)
par(mfrow=c(1,1))                                       # Restore display
```

```{r}
# Centrality scores can also be used with other sna routines, e.g., gplot
gplot(mids_1993, vertex.cex=(ideg+odeg)^0.5/2, vertex.sides=50, 
    boxed.labels=FALSE,label.cex=0.4, 
    vertex.col=rgb(odeg/max(odeg),0,ideg/max(ideg)), 
    label=network.vertex.names(mids_1993))
```

# Cognative Social Structures

**The Data**
David Krackhardt collected cognitive social structure data from 21 management personnel in a high-tech, machine manufacturing firm to assess the effects of a recent management intervention program. The relation queried was 

* “Who does X go to for advice and help with work?" (`krackad`) 
* “Who is a friend of X?" (`krackfr`). 

Each person indicated not only his or her own advice and friendship relationships, but also the relations he or she perceived among all other managers, generating a full 21 by 21 matrix of adjacency ratings from each person in the group.

```{r}
data(krack)
length(krack[[1]])
length(krack[[2]])
```

```{r}
par(mfrow=c(3,3),mar=c(0, 0, 0, 0) + 0.1)
for(i in 1:9)
plot(krack[[1]][[i]])
```

```{r}
kfr<-as.sociomatrix.sna((krack$krackfr))

## MDS of kfr for plotting below
# Can scale based on mis-matching rates using hdist with normalize=TRUE
kfr.dist<-hdist(kfr,normalize=TRUE)
plot(cmdscale(kfr.dist),type="n")        # Note the large cluster near 0,0
text(cmdscale(kfr.dist),label=1:21)

#-Network inference-------------------------------------------------------------
### Originally written by Carter Butts, UCI
### Modified by Zack Almquist, UMN
##
##
# Let's start by defining some priors for the Bayesian network inference
# model.  We'll use an uninformative network prior, together with weakly
# informative (but diffuse and symmetric) priors on the error rates.  Read
# the man page ("?bbnam") to get more information about how the routine works.
np<-matrix(0.5,21,21)  # 21 x 21 matrix of Bernoulli parameters (since n=21)
emp<-sapply(c(3,11),rep,21)  # Beta(3,11) priors for false negatives
epp<-sapply(c(3,11),rep,21)  # Beta(3,11) priors for false positives
hist(rbeta(100000,3,11))  # This gives you a sense of what the priors look like!

# Now, let's take some posterior draws for the friendship network, using 
# various models (warning: slow)
kfr.post.fixed<-bbnam.fixed(kfr,nprior=np,em=3/(3+11),ep=3/(3+11))
kfr.post.pooled<-bbnam.pooled(kfr,nprior=np,em=emp[1,],ep=epp[1,])
kfr.post.actor<-bbnam.actor(kfr,nprior=np,em=emp,ep=epp)

# Examine the results - note the difference that heterogeneity makes!
summary(kfr.post.fixed)
summary(kfr.post.pooled)
summary(kfr.post.actor)
plot(kfr.post.fixed)
plot(kfr.post.pooled)
plot(kfr.post.actor)

# Look at some of the error stats....
hist(as.vector(1-kfr.post.actor$em-kfr.post.actor$ep)) # Overall informativeness
mean(as.vector(1-kfr.post.actor$em-kfr.post.actor$ep)<0) # Neg. inf. rate
mean(as.vector(kfr.post.actor$em-kfr.post.actor$ep)>0) # Pr(em>ep)
plot(as.vector(kfr.post.actor$em),as.vector(kfr.post.actor$ep),xlim=c(0,1),
  ylim=c(0,1),cex=0.25)  # Plot em and em simultaneously
abline(1,-1,col=2)       # Color bounds on informative region
abline(h=0,v=0,col=2)
# With bias, most accurate persons not always in the center....
plot(cmdscale(kfr.dist),pch=19,col=rgb(1-apply(kfr.post.actor$em,2,mean),
  1-apply(kfr.post.actor$ep,2,mean),0),
  cex=3*(1-apply(kfr.post.actor$em+kfr.post.actor$ep,2,mean)))
cor((1-apply(kfr.post.actor$em+kfr.post.actor$ep,2,mean)),apply(kfr.dist,1,mean))

# Show some posterior predictive network properties
hist(gden(kfr.post.actor$net))                              #Density histogram
hist(grecip(kfr.post.actor$net,measure="edgewise.lrr"))     #Reciprocity
temp<-log(gtrans(kfr.post.actor$net)/gden(kfr.post.actor$net))
hist(temp)   # Log-odds multiplier measure of transitivity (>0 implies trans)

# Alternate approach: consensus method (MLE version)
kfr.conc<-consensus(kfr,method="romney.batchelder")

# Compare the results from the two estimation methods
hist(apply(kfr.post.actor$net,1,function(x){gcor(x,kfr.conc)})) #Posterior cor
gcor(apply(kfr.post.actor$net,c(2,3),median),kfr.conc)  #Point estimate
gplot(kfr.conc,displaylabels=T,boxed.lab=F)
gplot(apply(kfr.post.actor$net,c(2,3),median),displaylabels=T,boxed.lab=F)
```

For more details see: Butts, C. T. (2003). Network inference, error, and informant (in) accuracy: a Bayesian approach. social networks, 25(2), 103-140.